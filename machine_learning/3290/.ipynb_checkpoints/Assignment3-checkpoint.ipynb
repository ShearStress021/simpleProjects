{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3112b379-ea85-42c6-b526-93737968389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5b7829-a27a-426f-b3d7-2ee698d3988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Assignment 3: Text Documents, TF-IDF, CSR, SVD and KMeans\n",
    "# ------------------------------------------------------------\n",
    "# This script:\n",
    "# 1. Defines 5 short text documents.\n",
    "# 2. Builds the vocabulary and prints the index of each term.\n",
    "# 3. Constructs the term-document frequency matrix using CountVectorizer.\n",
    "# 4. Computes the TF-IDF matrix (dense and CSR/sparse forms).\n",
    "# 5. Applies 4 different (SVD + KMeans) pipelines and prints the clusters.\n",
    "# All steps use only tools and style consistent with the class notes.\n",
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8544fa4b-3f04-4b42-b82b-2f81a2afa27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DOCUMENTS ===\n",
      "Doc1: This session talks about CSR\n",
      "Doc2: SVD works with CSR\n",
      "Doc3: Kmeans clustering can be used in a pipeline\n",
      "Doc4: pipeline can have any clustering approach\n",
      "Doc5: TFIDF needs CSR\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Define the documents\n",
    "docs = [\n",
    "    \"This session talks about CSR\",\n",
    "    \"SVD works with CSR\",\n",
    "    \"Kmeans clustering can be used in a pipeline\",\n",
    "    \"pipeline can have any clustering approach\",\n",
    "    \"TFIDF needs CSR\"\n",
    "]\n",
    "\n",
    "titles = [\"Doc1\", \"Doc2\", \"Doc3\", \"Doc4\", \"Doc5\"]\n",
    "\n",
    "print(\"=== DOCUMENTS ===\")\n",
    "for t, d in zip(titles, docs):\n",
    "    print(f\"{t}: {d}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d001233-4950-4498-bfa2-a95483214543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TERM INDEX (from TfidfVectorizer) ===\n",
      "0 -> about\n",
      "1 -> any\n",
      "2 -> approach\n",
      "3 -> be\n",
      "4 -> can\n",
      "5 -> clustering\n",
      "6 -> csr\n",
      "7 -> have\n",
      "8 -> in\n",
      "9 -> kmeans\n",
      "10 -> needs\n",
      "11 -> pipeline\n",
      "12 -> session\n",
      "13 -> svd\n",
      "14 -> talks\n",
      "15 -> tfidf\n",
      "16 -> this\n",
      "17 -> used\n",
      "18 -> with\n",
      "19 -> works\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 2) Term index using TF-IDF vocabulary\n",
    "# ------------------------------------------------------------\n",
    "# We first fit a TfidfVectorizer to learn the vocabulary.\n",
    "# Then we print each term with its column index in the TF-IDF matrix.\n",
    "\n",
    "tf = TfidfVectorizer()\n",
    "tfidf_csr = tf.fit_transform(docs)      # TF-IDF in sparse (CSR) format\n",
    "terms = tf.get_feature_names_out()      # learned vocabulary (sorted by index)\n",
    "\n",
    "print(\"=== TERM INDEX (from TfidfVectorizer) ===\")\n",
    "for idx, term in enumerate(terms):\n",
    "    print(f\"{idx} -> {term}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "820bd985-35c7-43a4-9236-a4053f9d2b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COUNT VECTORIZER VOCABULARY ===\n",
      "{'this': 16, 'session': 12, 'talks': 14, 'about': 0, 'csr': 6, 'svd': 13, 'works': 19, 'with': 18, 'kmeans': 9, 'clustering': 5, 'can': 4, 'be': 3, 'used': 17, 'in': 8, 'pipeline': 11, 'have': 7, 'any': 1, 'approach': 2, 'tfidf': 15, 'needs': 10}\n",
      "\n",
      "\n",
      "=== FREQUENCY MATRIX (array) ===\n",
      "[[1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1]\n",
      " [0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0]\n",
      " [0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3) Term-Document Frequency Matrix (CountVectorizer)\n",
    "# ------------------------------------------------------------\n",
    "# Here we use CountVectorizer to obtain raw term frequencies.\n",
    "# Rows correspond to documents, columns correspond to terms.\n",
    "\n",
    "cv = CountVectorizer()\n",
    "freq_csr = cv.fit_transform(docs)\n",
    "\n",
    "freq_array = freq_csr.toarray()\n",
    "freq_terms = cv.get_feature_names_out()\n",
    "\n",
    "print(\"=== COUNT VECTORIZER VOCABULARY ===\")\n",
    "print(cv.vocabulary_)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== FREQUENCY MATRIX (array) ===\")\n",
    "print(freq_array)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab812ed-761e-4987-9975-ce767263581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FREQUENCY MATRIX (DataFrame) ===\n",
      "      about  any  approach  be  can  clustering  csr  have  in  kmeans  needs  \\\n",
      "Doc1      1    0         0   0    0           0    1     0   0       0      0   \n",
      "Doc2      0    0         0   0    0           0    1     0   0       0      0   \n",
      "Doc3      0    0         0   1    1           1    0     0   1       1      0   \n",
      "Doc4      0    1         1   0    1           1    0     1   0       0      0   \n",
      "Doc5      0    0         0   0    0           0    1     0   0       0      1   \n",
      "\n",
      "      pipeline  session  svd  talks  tfidf  this  used  with  works  \n",
      "Doc1         0        1    0      1      0     1     0     0      0  \n",
      "Doc2         0        0    1      0      0     0     0     1      1  \n",
      "Doc3         1        0    0      0      0     0     1     0      0  \n",
      "Doc4         1        0    0      0      0     0     0     0      0  \n",
      "Doc5         0        0    0      0      1     0     0     0      0  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Present frequency matrix as a DataFrame for readability\n",
    "freq_df = pd.DataFrame(freq_array, columns=freq_terms, index=titles)\n",
    "\n",
    "print(\"=== FREQUENCY MATRIX (DataFrame) ===\")\n",
    "print(freq_df)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9448f1eb-7bc8-40e5-add7-a51715933f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TF-IDF MATRIX (Dense, DataFrame) ===\n",
      "         about       any  approach        be       can  clustering       csr  \\\n",
      "Doc1  0.474125  0.000000  0.000000  0.000000  0.000000    0.000000  0.317527   \n",
      "Doc2  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000  0.360638   \n",
      "Doc3  0.000000  0.000000  0.000000  0.409865  0.330677    0.330677  0.000000   \n",
      "Doc4  0.000000  0.449342  0.449342  0.000000  0.362526    0.362526  0.000000   \n",
      "Doc5  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000  0.427993   \n",
      "\n",
      "          have        in    kmeans    needs  pipeline   session       svd  \\\n",
      "Doc1  0.000000  0.000000  0.000000  0.00000  0.000000  0.474125  0.000000   \n",
      "Doc2  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.538498   \n",
      "Doc3  0.000000  0.409865  0.409865  0.00000  0.330677  0.000000  0.000000   \n",
      "Doc4  0.449342  0.000000  0.000000  0.00000  0.362526  0.000000  0.000000   \n",
      "Doc5  0.000000  0.000000  0.000000  0.63907  0.000000  0.000000  0.000000   \n",
      "\n",
      "         talks    tfidf      this      used      with     works  \n",
      "Doc1  0.474125  0.00000  0.474125  0.000000  0.000000  0.000000  \n",
      "Doc2  0.000000  0.00000  0.000000  0.000000  0.538498  0.538498  \n",
      "Doc3  0.000000  0.00000  0.000000  0.409865  0.000000  0.000000  \n",
      "Doc4  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n",
      "Doc5  0.000000  0.63907  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "\n",
      "=== TF-IDF MATRIX (CSR / Sparse representation) ===\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 25 stored elements and shape (5, 20)>\n",
      "  Coords\tValues\n",
      "  (0, 16)\t0.4741246485558491\n",
      "  (0, 12)\t0.4741246485558491\n",
      "  (0, 14)\t0.4741246485558491\n",
      "  (0, 0)\t0.4741246485558491\n",
      "  (0, 6)\t0.31752680284846835\n",
      "  (1, 6)\t0.3606383263504801\n",
      "  (1, 13)\t0.5384979101064753\n",
      "  (1, 19)\t0.5384979101064753\n",
      "  (1, 18)\t0.5384979101064753\n",
      "  (2, 9)\t0.40986538560224284\n",
      "  (2, 5)\t0.33067681238156543\n",
      "  (2, 4)\t0.33067681238156543\n",
      "  (2, 3)\t0.40986538560224284\n",
      "  (2, 17)\t0.40986538560224284\n",
      "  (2, 8)\t0.40986538560224284\n",
      "  (2, 11)\t0.33067681238156543\n",
      "  (3, 5)\t0.36252617931707143\n",
      "  (3, 4)\t0.36252617931707143\n",
      "  (3, 11)\t0.36252617931707143\n",
      "  (3, 7)\t0.4493418549869351\n",
      "  (3, 1)\t0.4493418549869351\n",
      "  (3, 2)\t0.4493418549869351\n",
      "  (4, 6)\t0.42799292268317357\n",
      "  (4, 15)\t0.6390704413963749\n",
      "  (4, 10)\t0.6390704413963749\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4) TF-IDF Matrix: Dense + CSR (Sparse) Representations\n",
    "# ------------------------------------------------------------\n",
    "# TfidfVectorizer already returned a CSR sparse matrix (tfidf_csr).\n",
    "# We show both:\n",
    "# - dense TF-IDF matrix (for interpretation),\n",
    "# - CSR structure (to emphasize sparse representation).\n",
    "\n",
    "tfidf_dense = tfidf_csr.toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_dense, columns=terms, index=titles)\n",
    "\n",
    "print(\"=== TF-IDF MATRIX (Dense, DataFrame) ===\")\n",
    "print(tfidf_df)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== TF-IDF MATRIX (CSR / Sparse representation) ===\")\n",
    "print(tfidf_csr)   # compressed sparse row format (row, col, value)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "697bfa7d-0339-4c8d-bf71-b565c3b772c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPLICIT CSR FROM DENSE TF-IDF (should match above structurally) ===\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 25 stored elements and shape (5, 20)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t0.4741246485558491\n",
      "  (0, 6)\t0.31752680284846835\n",
      "  (0, 12)\t0.4741246485558491\n",
      "  (0, 14)\t0.4741246485558491\n",
      "  (0, 16)\t0.4741246485558491\n",
      "  (1, 6)\t0.3606383263504801\n",
      "  (1, 13)\t0.5384979101064753\n",
      "  (1, 18)\t0.5384979101064753\n",
      "  (1, 19)\t0.5384979101064753\n",
      "  (2, 3)\t0.40986538560224284\n",
      "  (2, 4)\t0.33067681238156543\n",
      "  (2, 5)\t0.33067681238156543\n",
      "  (2, 8)\t0.40986538560224284\n",
      "  (2, 9)\t0.40986538560224284\n",
      "  (2, 11)\t0.33067681238156543\n",
      "  (2, 17)\t0.40986538560224284\n",
      "  (3, 1)\t0.4493418549869351\n",
      "  (3, 2)\t0.4493418549869351\n",
      "  (3, 4)\t0.36252617931707143\n",
      "  (3, 5)\t0.36252617931707143\n",
      "  (3, 7)\t0.4493418549869351\n",
      "  (3, 11)\t0.36252617931707143\n",
      "  (4, 6)\t0.42799292268317357\n",
      "  (4, 10)\t0.6390704413963749\n",
      "  (4, 15)\t0.6390704413963749\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explicit CSR from dense, just to illustrate the same structure\n",
    "tfidf_csr_explicit = csr_matrix(tfidf_dense)\n",
    "print(\"=== EXPLICIT CSR FROM DENSE TF-IDF (should match above structurally) ===\")\n",
    "print(tfidf_csr_explicit)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ada524ae-1011-40eb-9935-e9d78f5be6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5) SVD + KMeans Pipelines (4 scenarios)\n",
    "# ------------------------------------------------------------\n",
    "# We now reduce dimensionality of the TF-IDF matrix using TruncatedSVD,\n",
    "# then cluster the documents using KMeans.\n",
    "#\n",
    "# Four scenarios:\n",
    "#   1) SVD with 2 components, KMeans with 2 clusters\n",
    "#   2) SVD with 3 components, KMeans with 2 clusters\n",
    "#   3) SVD with 2 components, KMeans with 3 clusters\n",
    "#   4) SVD with 3 components, KMeans with 3 clusters\n",
    "#\n",
    "# For each scenario, we:\n",
    "# - build a pipeline: [TruncatedSVD -> KMeans]\n",
    "# - fit on the TF-IDF matrix\n",
    "# - predict cluster labels for each document\n",
    "# - print a table with document, scenario, and assigned cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3d6b5c2-3799-4761-a759-b0605d649e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\n",
    "    (2, 2),\n",
    "    (3, 2),\n",
    "    (2, 3),\n",
    "    (3, 3)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6254824-4294-4c4c-9835-da77ddc5272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []  # to store DataFrames for all scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61729c72-ae70-4983-b9af-e78256cfb83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVD + KMeans CLUSTERING RESULTS ===\n",
      "  Title                                     Document         Scenario  Cluster\n",
      "0  Doc1                 This session talks about CSR  SVD=2, KMeans=2        0\n",
      "1  Doc2                           SVD works with CSR  SVD=2, KMeans=2        0\n",
      "4  Doc5                              TFIDF needs CSR  SVD=2, KMeans=2        0\n",
      "2  Doc3  Kmeans clustering can be used in a pipeline  SVD=2, KMeans=2        1\n",
      "3  Doc4    pipeline can have any clustering approach  SVD=2, KMeans=2        1\n",
      "------------------------------------------------------------\n",
      "  Title                                     Document         Scenario  Cluster\n",
      "1  Doc2                           SVD works with CSR  SVD=3, KMeans=2        0\n",
      "4  Doc5                              TFIDF needs CSR  SVD=3, KMeans=2        0\n",
      "2  Doc3  Kmeans clustering can be used in a pipeline  SVD=3, KMeans=2        1\n",
      "0  Doc1                 This session talks about CSR  SVD=3, KMeans=2        1\n",
      "3  Doc4    pipeline can have any clustering approach  SVD=3, KMeans=2        1\n",
      "------------------------------------------------------------\n",
      "  Title                                     Document         Scenario  Cluster\n",
      "1  Doc2                           SVD works with CSR  SVD=2, KMeans=3        0\n",
      "4  Doc5                              TFIDF needs CSR  SVD=2, KMeans=3        0\n",
      "3  Doc4    pipeline can have any clustering approach  SVD=2, KMeans=3        1\n",
      "2  Doc3  Kmeans clustering can be used in a pipeline  SVD=2, KMeans=3        1\n",
      "0  Doc1                 This session talks about CSR  SVD=2, KMeans=3        2\n",
      "------------------------------------------------------------\n",
      "  Title                                     Document         Scenario  Cluster\n",
      "1  Doc2                           SVD works with CSR  SVD=3, KMeans=3        0\n",
      "4  Doc5                              TFIDF needs CSR  SVD=3, KMeans=3        0\n",
      "3  Doc4    pipeline can have any clustering approach  SVD=3, KMeans=3        1\n",
      "2  Doc3  Kmeans clustering can be used in a pipeline  SVD=3, KMeans=3        1\n",
      "0  Doc1                 This session talks about CSR  SVD=3, KMeans=3        2\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilkeb\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilkeb\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilkeb\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ilkeb\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=== SVD + KMeans CLUSTERING RESULTS ===\")\n",
    "\n",
    "for n_comp, n_clusters in scenarios:\n",
    "    # Create SVD and KMeans with given parameters\n",
    "    svd = TruncatedSVD(n_components=n_comp)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "    # Create pipeline: first SVD, then KMeans\n",
    "    pipe = make_pipeline(svd, kmeans)\n",
    "\n",
    "    # Fit the pipeline on TF-IDF features\n",
    "    pipe.fit(tfidf_csr)\n",
    "\n",
    "    # Predict cluster for each document\n",
    "    labels = pipe.predict(tfidf_csr)\n",
    "\n",
    "    # Build result DataFrame for this scenario\n",
    "    df_result = pd.DataFrame({\n",
    "        \"Title\": titles,\n",
    "        \"Document\": docs,\n",
    "        \"Scenario\": f\"SVD={n_comp}, KMeans={n_clusters}\",\n",
    "        \"Cluster\": labels\n",
    "    })\n",
    "\n",
    "    # Sort by cluster label for clearer grouping\n",
    "    df_sorted = df_result.sort_values(\"Cluster\")\n",
    "\n",
    "    print(df_sorted)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Save for potential further analysis\n",
    "    results.append(df_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10bb5b9-f109-4fca-8c49-c124c1a29d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
