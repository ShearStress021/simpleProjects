{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a31949ed-58b8-4fd0-81d3-e2fbd70f7b92",
   "metadata": {},
   "source": [
    "#  Using NLTK for Text Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f966d-fb8b-4e19-977a-0957d4bb03a2",
   "metadata": {},
   "source": [
    "### import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2b8934-e772-442a-b169-04a8b92d5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b78ee-50be-4f3a-9b6a-0b0140b4cfb9",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9efcf477-b3f2-4919-98d0-11001c823d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\kanja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d555681-4aae-4e5c-b7a7-d5e82c064f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6604941e-64f9-4069-adea-a20476041495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordListCorpusReader in 'C:\\\\Users\\\\kanja\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\names'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb476c1-7a41-481e-8311-6b6fdcb7dc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female.txt', 'male.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a96f0c-9030-4e89-9a5d-e299d17ea600",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_names = name_list.words('male.txt')\n",
    "female_names = name_list.words('female.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb36a94c-95f8-4d55-adf6-9eda593a2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_names = ([(name, 'male') for name in male_names] +\n",
    "                 [(name, 'female') for name in female_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afdd23ec-1744-45c1-a199-d04d0436aedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e693b1f-6b43-432c-a10e-0ada8b7eb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "844493ca-26f2-4c33-ad75-5dca8a987681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6444, 1000, 500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names   = labeled_names[1500:]\n",
    "devtest_names = labeled_names[500:1500]\n",
    "test_names    = labeled_names[:500]\n",
    "len(train_names), len(devtest_names), len(test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d09002-a79d-4d94-b95f-3133c55d75e0",
   "metadata": {},
   "source": [
    "### Features Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "911d6083-e309-4798-9213-84a13e133671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor1(name):\n",
    "    name = name.lower()\n",
    "    return {\n",
    "        \"lastletter\" : name[-1],\n",
    "        \"name_length\" : len(name),\n",
    "        \"firstletter\": name[0],\n",
    "        \"last_two_letter\" : name[-2:],\n",
    "        \"last_letter_vowel\": name[-1] in \"aeiou\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dbb0775-71d5-450c-941e-df61cb53d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor2(name):\n",
    "    features = {}\n",
    "    name = name.lower()\n",
    "    features[\"firstletter\"] = name[0]\n",
    "    features[\"lastletter\"] = name[-1]\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[f\"count ({letter})\"] = name.count(letter)\n",
    "        features[f\"has({letter})\"] = (letter in name)\n",
    "    return features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa808c86-eea4-4517-a456-b58ab0604207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lastletter': 'k', 'name_length': 5, 'firstletter': 's', 'last_two_letter': 'ek', 'last_letter_vowel': False}\n",
      "\n",
      "{'firstletter': 'j', 'lastletter': 'n', 'count (a)': 0, 'has(a)': False, 'count (b)': 0, 'has(b)': False, 'count (c)': 0, 'has(c)': False, 'count (d)': 0, 'has(d)': False, 'count (e)': 0, 'has(e)': False, 'count (f)': 0, 'has(f)': False, 'count (g)': 0, 'has(g)': False, 'count (h)': 1, 'has(h)': True, 'count (i)': 0, 'has(i)': False, 'count (j)': 1, 'has(j)': True, 'count (k)': 0, 'has(k)': False, 'count (l)': 0, 'has(l)': False, 'count (m)': 0, 'has(m)': False, 'count (n)': 1, 'has(n)': True, 'count (o)': 1, 'has(o)': True, 'count (p)': 0, 'has(p)': False, 'count (q)': 0, 'has(q)': False, 'count (r)': 0, 'has(r)': False, 'count (s)': 0, 'has(s)': False, 'count (t)': 0, 'has(t)': False, 'count (u)': 0, 'has(u)': False, 'count (v)': 0, 'has(v)': False, 'count (w)': 0, 'has(w)': False, 'count (x)': 0, 'has(x)': False, 'count (y)': 0, 'has(y)': False, 'count (z)': 0, 'has(z)': False}\n",
      "\n",
      "{'lastletter': 'h', 'name_length': 9, 'firstletter': 'e', 'last_two_letter': 'th', 'last_letter_vowel': False}\n",
      "\n",
      "{'firstletter': 'j', 'lastletter': 'e', 'count (a)': 1, 'has(a)': True, 'count (b)': 0, 'has(b)': False, 'count (c)': 0, 'has(c)': False, 'count (d)': 0, 'has(d)': False, 'count (e)': 1, 'has(e)': True, 'count (f)': 0, 'has(f)': False, 'count (g)': 0, 'has(g)': False, 'count (h)': 0, 'has(h)': False, 'count (i)': 0, 'has(i)': False, 'count (j)': 1, 'has(j)': True, 'count (k)': 0, 'has(k)': False, 'count (l)': 0, 'has(l)': False, 'count (m)': 0, 'has(m)': False, 'count (n)': 1, 'has(n)': True, 'count (o)': 0, 'has(o)': False, 'count (p)': 0, 'has(p)': False, 'count (q)': 0, 'has(q)': False, 'count (r)': 0, 'has(r)': False, 'count (s)': 0, 'has(s)': False, 'count (t)': 0, 'has(t)': False, 'count (u)': 0, 'has(u)': False, 'count (v)': 0, 'has(v)': False, 'count (w)': 0, 'has(w)': False, 'count (x)': 0, 'has(x)': False, 'count (y)': 0, 'has(y)': False, 'count (z)': 0, 'has(z)': False}\n"
     ]
    }
   ],
   "source": [
    "print(feature_extractor1(\"Shrek\"))\n",
    "print()\n",
    "print(feature_extractor2(\"John\"))\n",
    "print()\n",
    "print(feature_extractor1(\"Elizabeth\"))\n",
    "print()\n",
    "print(feature_extractor2(\"Jane\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc80a14e-fa21-4291-a264-e65068c1c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to apply the feature extractor\n",
    "def apply_feature(feature_fn, label_list):\n",
    "    return [(feature_fn(n), g) for (n,g) in label_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778550f0-9932-4fa4-8d21-9fd8f4ab5101",
   "metadata": {},
   "source": [
    "### Model Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "901c5810-c05a-47d7-b79a-468d30e556e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_error_samples(errors, max_samples=20):\n",
    "    \"\"\"Print a sample of misclassified names.\"\"\"\n",
    "    print(\"\\nNumber of dev errors:\", len(errors))\n",
    "    print(f\"\\nSample errors (first {max_samples}):\")\n",
    "    for (true_label, guess, name) in sorted(errors)[:max_samples]:\n",
    "        print(f\"correct={true_label} guess={guess} name={name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74e34712-1c13-4303-adc8-9c802abdb44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if class need a\n",
    "import inspect\n",
    "\n",
    "def requires_arguments(cls):\n",
    "    sig = inspect.signature(cls.__init__)\n",
    "    args = sig.parameters\n",
    "    return len(args) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "340a5349-9df8-48dc-aefa-89064dcd1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(clf, clf_name, feature_fn, feature_name):\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{clf_name}  |  Features: {feature_name}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # prepare feature sets\n",
    "    # train_set   = apply_feature(feature_fn, train_names)\n",
    "    devtest_set = apply_feature(feature_fn, devtest_names)\n",
    "    test_set    = apply_feature(feature_fn, test_names)\n",
    "    \n",
    "    # train the classifier\n",
    "\n",
    "    if requires_arguments(clf):\n",
    "        train_set   = apply_feature(feature_fn, train_names)\n",
    "        classifier = clf.train(train_set)\n",
    "    else:\n",
    "        classifier = clf\n",
    "    \n",
    "    # compute accuracy on dev and test sets\n",
    "    dev_acc  = nltk.classify.accuracy(classifier, devtest_set)\n",
    "    test_acc = nltk.classify.accuracy(classifier, test_set)\n",
    "    print(f\"Dev accuracy : {dev_acc:.3f}\")\n",
    "    print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "    \n",
    "    # build error list on the dev set\n",
    "    errors = []\n",
    "    for (name, true_label) in devtest_names:\n",
    "        guess = classifier.classify(feature_fn(name))\n",
    "        if guess != true_label:\n",
    "            errors.append((true_label, guess, name))\n",
    "    \n",
    "    # print a subset of errors\n",
    "    print_error_samples(errors, max_samples=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa24b25-a7d6-4a35-975f-6d747948a662",
   "metadata": {},
   "source": [
    "### Model One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb7e28dc-f89a-4b4e-8850-386579159e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Nltk DecisionTreeClassifier  |  Features: Feature Set 1 (last_letter/name length/firstletter/end_vowel)\n",
      "--------------------------------------------------------------------------------\n",
      "Dev accuracy : 0.776\n",
      "Test accuracy: 0.716\n",
      "\n",
      "Number of dev errors: 224\n",
      "\n",
      "Sample errors (first 20):\n",
      "correct=female guess=male name=Abbe\n",
      "correct=female guess=male name=Adore\n",
      "correct=female guess=male name=Ali\n",
      "correct=female guess=male name=Allie\n",
      "correct=female guess=male name=Amargo\n",
      "correct=female guess=male name=Andromache\n",
      "correct=female guess=male name=Anne-Mar\n",
      "correct=female guess=male name=Anni\n",
      "correct=female guess=male name=Ariel\n",
      "correct=female guess=male name=Audre\n",
      "correct=female guess=male name=Aurie\n",
      "correct=female guess=male name=Bebe\n",
      "correct=female guess=male name=Becky\n",
      "correct=female guess=male name=Belle\n",
      "correct=female guess=male name=Bevvy\n",
      "correct=female guess=male name=Bobine\n",
      "correct=female guess=male name=Britt\n",
      "correct=female guess=male name=Caril\n",
      "correct=female guess=male name=Carmon\n",
      "correct=female guess=male name=Chicky\n"
     ]
    }
   ],
   "source": [
    "train_set   = apply_feature(feature_extractor1, train_names)\n",
    "classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "\n",
    "train_and_evaluate(classifier, \"Nltk DecisionTreeClassifier\", feature_extractor1, \"Feature Set 1 (last_letter/name length/firstletter/end_vowel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de1fc855-b107-47e3-ba5c-a79f108c6b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Nltk DecisionTreeClassifier  |  Features: Feature Set 2 (first/last/counters)\n",
      "--------------------------------------------------------------------------------\n",
      "Dev accuracy : 0.812\n",
      "Test accuracy: 0.758\n",
      "\n",
      "Number of dev errors: 188\n",
      "\n",
      "Sample errors (first 20):\n",
      "correct=female guess=male name=Ali\n",
      "correct=female guess=male name=Amargo\n",
      "correct=female guess=male name=Anne-Mar\n",
      "correct=female guess=male name=Aphrodite\n",
      "correct=female guess=male name=Aprilette\n",
      "correct=female guess=male name=Ashlen\n",
      "correct=female guess=male name=Ashli\n",
      "correct=female guess=male name=Becky\n",
      "correct=female guess=male name=Blinny\n",
      "correct=female guess=male name=Charlott\n",
      "correct=female guess=male name=Cindelyn\n",
      "correct=female guess=male name=Darb\n",
      "correct=female guess=male name=Deb\n",
      "correct=female guess=male name=Denys\n",
      "correct=female guess=male name=Doloritas\n",
      "correct=female guess=male name=Dorian\n",
      "correct=female guess=male name=Easter\n",
      "correct=female guess=male name=Em\n",
      "correct=female guess=male name=Flo\n",
      "correct=female guess=male name=Flor\n"
     ]
    }
   ],
   "source": [
    "train_set   = apply_feature(feature_extractor2, train_names)\n",
    "classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "\n",
    "train_and_evaluate(classifier, \"Nltk DecisionTreeClassifier\", feature_extractor2, \"Feature Set 2 (first/last/counters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2eaaae-6f80-407d-848e-32178543b0be",
   "metadata": {},
   "source": [
    "### Model Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57b29599-d76e-4728-97e7-1d5b231f287f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.370\n",
      "             2          -0.42935        0.791\n",
      "             3          -0.37452        0.805\n",
      "             4          -0.34920        0.807\n",
      "             5          -0.33464        0.810\n",
      "             6          -0.32513        0.813\n",
      "             7          -0.31840        0.816\n",
      "             8          -0.31338        0.816\n",
      "             9          -0.30949        0.819\n",
      "            10          -0.30639        0.820\n",
      "            11          -0.30386        0.821\n",
      "            12          -0.30175        0.822\n",
      "            13          -0.29998        0.823\n",
      "            14          -0.29846        0.822\n",
      "            15          -0.29715        0.822\n",
      "            16          -0.29601        0.822\n",
      "            17          -0.29501        0.821\n",
      "            18          -0.29412        0.821\n",
      "            19          -0.29333        0.821\n",
      "            20          -0.29262        0.822\n",
      "            21          -0.29198        0.822\n",
      "            22          -0.29140        0.822\n",
      "            23          -0.29087        0.822\n",
      "            24          -0.29039        0.823\n",
      "            25          -0.28994        0.823\n",
      "            26          -0.28954        0.824\n",
      "            27          -0.28916        0.824\n",
      "            28          -0.28881        0.824\n",
      "            29          -0.28849        0.824\n",
      "            30          -0.28818        0.824\n",
      "            31          -0.28790        0.823\n",
      "            32          -0.28763        0.823\n",
      "            33          -0.28739        0.824\n",
      "            34          -0.28715        0.824\n",
      "            35          -0.28693        0.824\n",
      "            36          -0.28672        0.823\n",
      "            37          -0.28653        0.823\n",
      "            38          -0.28634        0.824\n",
      "            39          -0.28616        0.824\n",
      "            40          -0.28599        0.824\n",
      "            41          -0.28583        0.824\n",
      "            42          -0.28568        0.824\n",
      "            43          -0.28554        0.824\n",
      "            44          -0.28540        0.824\n",
      "            45          -0.28527        0.824\n",
      "            46          -0.28514        0.824\n",
      "            47          -0.28502        0.824\n",
      "            48          -0.28490        0.824\n",
      "            49          -0.28479        0.824\n",
      "            50          -0.28469        0.824\n",
      "            51          -0.28458        0.824\n",
      "            52          -0.28449        0.824\n",
      "            53          -0.28439        0.824\n",
      "            54          -0.28430        0.824\n",
      "            55          -0.28421        0.824\n",
      "            56          -0.28413        0.824\n",
      "            57          -0.28405        0.824\n",
      "            58          -0.28397        0.824\n",
      "            59          -0.28389        0.824\n",
      "            60          -0.28382        0.824\n",
      "            61          -0.28375        0.824\n",
      "            62          -0.28368        0.824\n",
      "            63          -0.28361        0.824\n",
      "            64          -0.28354        0.824\n",
      "            65          -0.28348        0.824\n",
      "            66          -0.28342        0.824\n",
      "            67          -0.28336        0.824\n",
      "            68          -0.28330        0.824\n",
      "            69          -0.28325        0.824\n",
      "            70          -0.28320        0.824\n",
      "            71          -0.28314        0.824\n",
      "            72          -0.28309        0.824\n",
      "            73          -0.28304        0.824\n",
      "            74          -0.28299        0.824\n",
      "            75          -0.28295        0.824\n",
      "            76          -0.28290        0.824\n",
      "            77          -0.28286        0.824\n",
      "            78          -0.28281        0.824\n",
      "            79          -0.28277        0.824\n",
      "            80          -0.28273        0.824\n",
      "            81          -0.28269        0.824\n",
      "            82          -0.28265        0.824\n",
      "            83          -0.28261        0.824\n",
      "            84          -0.28257        0.824\n",
      "            85          -0.28254        0.824\n",
      "            86          -0.28250        0.824\n",
      "            87          -0.28247        0.824\n",
      "            88          -0.28243        0.824\n",
      "            89          -0.28240        0.824\n",
      "            90          -0.28237        0.824\n",
      "            91          -0.28233        0.824\n",
      "            92          -0.28230        0.824\n",
      "            93          -0.28227        0.824\n",
      "            94          -0.28224        0.824\n",
      "            95          -0.28221        0.824\n",
      "            96          -0.28218        0.824\n",
      "            97          -0.28216        0.824\n",
      "            98          -0.28213        0.824\n",
      "            99          -0.28210        0.824\n",
      "         Final          -0.28207        0.824\n",
      "================================================================================\n",
      "Nltk ConditionalExponentialClassifier  |  Features: Feature Set 1 (last_letter/name length/firstletter/end_vowel)\n",
      "--------------------------------------------------------------------------------\n",
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.370\n",
      "             2          -0.42935        0.791\n",
      "             3          -0.37452        0.805\n",
      "             4          -0.34920        0.807\n",
      "             5          -0.33464        0.810\n",
      "             6          -0.32513        0.813\n",
      "             7          -0.31840        0.816\n",
      "             8          -0.31338        0.816\n",
      "             9          -0.30949        0.819\n",
      "            10          -0.30639        0.820\n",
      "            11          -0.30386        0.821\n",
      "            12          -0.30175        0.822\n",
      "            13          -0.29998        0.823\n",
      "            14          -0.29846        0.822\n",
      "            15          -0.29715        0.822\n",
      "            16          -0.29601        0.822\n",
      "            17          -0.29501        0.821\n",
      "            18          -0.29412        0.821\n",
      "            19          -0.29333        0.821\n",
      "            20          -0.29262        0.822\n",
      "            21          -0.29198        0.822\n",
      "            22          -0.29140        0.822\n",
      "            23          -0.29087        0.822\n",
      "            24          -0.29039        0.823\n",
      "            25          -0.28994        0.823\n",
      "            26          -0.28954        0.824\n",
      "            27          -0.28916        0.824\n",
      "            28          -0.28881        0.824\n",
      "            29          -0.28849        0.824\n",
      "            30          -0.28818        0.824\n",
      "            31          -0.28790        0.823\n",
      "            32          -0.28763        0.823\n",
      "            33          -0.28739        0.824\n",
      "            34          -0.28715        0.824\n",
      "            35          -0.28693        0.824\n",
      "            36          -0.28672        0.823\n",
      "            37          -0.28653        0.823\n",
      "            38          -0.28634        0.824\n",
      "            39          -0.28616        0.824\n",
      "            40          -0.28599        0.824\n",
      "            41          -0.28583        0.824\n",
      "            42          -0.28568        0.824\n",
      "            43          -0.28554        0.824\n",
      "            44          -0.28540        0.824\n",
      "            45          -0.28527        0.824\n",
      "            46          -0.28514        0.824\n",
      "            47          -0.28502        0.824\n",
      "            48          -0.28490        0.824\n",
      "            49          -0.28479        0.824\n",
      "            50          -0.28469        0.824\n",
      "            51          -0.28458        0.824\n",
      "            52          -0.28449        0.824\n",
      "            53          -0.28439        0.824\n",
      "            54          -0.28430        0.824\n",
      "            55          -0.28421        0.824\n",
      "            56          -0.28413        0.824\n",
      "            57          -0.28405        0.824\n",
      "            58          -0.28397        0.824\n",
      "            59          -0.28389        0.824\n",
      "            60          -0.28382        0.824\n",
      "            61          -0.28375        0.824\n",
      "            62          -0.28368        0.824\n",
      "            63          -0.28361        0.824\n",
      "            64          -0.28354        0.824\n",
      "            65          -0.28348        0.824\n",
      "            66          -0.28342        0.824\n",
      "            67          -0.28336        0.824\n",
      "            68          -0.28330        0.824\n",
      "            69          -0.28325        0.824\n",
      "            70          -0.28320        0.824\n",
      "            71          -0.28314        0.824\n",
      "            72          -0.28309        0.824\n",
      "            73          -0.28304        0.824\n",
      "            74          -0.28299        0.824\n",
      "            75          -0.28295        0.824\n",
      "            76          -0.28290        0.824\n",
      "            77          -0.28286        0.824\n",
      "            78          -0.28281        0.824\n",
      "            79          -0.28277        0.824\n",
      "            80          -0.28273        0.824\n",
      "            81          -0.28269        0.824\n",
      "            82          -0.28265        0.824\n",
      "            83          -0.28261        0.824\n",
      "            84          -0.28257        0.824\n",
      "            85          -0.28254        0.824\n",
      "            86          -0.28250        0.824\n",
      "            87          -0.28247        0.824\n",
      "            88          -0.28243        0.824\n",
      "            89          -0.28240        0.824\n",
      "            90          -0.28237        0.824\n",
      "            91          -0.28233        0.824\n",
      "            92          -0.28230        0.824\n",
      "            93          -0.28227        0.824\n",
      "            94          -0.28224        0.824\n",
      "            95          -0.28221        0.824\n",
      "            96          -0.28218        0.824\n",
      "            97          -0.28216        0.824\n",
      "            98          -0.28213        0.824\n",
      "            99          -0.28210        0.824\n",
      "         Final          -0.28207        0.824\n",
      "Dev accuracy : 0.792\n",
      "Test accuracy: 0.770\n",
      "\n",
      "Number of dev errors: 208\n",
      "\n",
      "Sample errors (first 20):\n",
      "correct=female guess=male name=Abbe\n",
      "correct=female guess=male name=Amargo\n",
      "correct=female guess=male name=Anne-Mar\n",
      "correct=female guess=male name=Babs\n",
      "correct=female guess=male name=Bebe\n",
      "correct=female guess=male name=Becky\n",
      "correct=female guess=male name=Bevvy\n",
      "correct=female guess=male name=Blondell\n",
      "correct=female guess=male name=Britt\n",
      "correct=female guess=male name=Carmon\n",
      "correct=female guess=male name=Charlott\n",
      "correct=female guess=male name=Darb\n",
      "correct=female guess=male name=Deb\n",
      "correct=female guess=male name=Doloritas\n",
      "correct=female guess=male name=Dorian\n",
      "correct=female guess=male name=Easter\n",
      "correct=female guess=male name=Em\n",
      "correct=female guess=male name=Evy\n",
      "correct=female guess=male name=Flo\n",
      "correct=female guess=male name=Flor\n"
     ]
    }
   ],
   "source": [
    "train_set   = apply_feature(feature_extractor1, train_names)\n",
    "classifier = nltk.ConditionalExponentialClassifier.train(train_set)\n",
    "\n",
    "train_and_evaluate(classifier, \"Nltk ConditionalExponentialClassifier\", feature_extractor1,  \"Feature Set 1 (last_letter/name length/firstletter/end_vowel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d403cf77-a195-434d-9e37-c59798f661ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.370\n",
      "             2          -0.42935        0.791\n",
      "             3          -0.37452        0.805\n",
      "             4          -0.34920        0.807\n",
      "             5          -0.33464        0.810\n",
      "             6          -0.32513        0.813\n",
      "             7          -0.31840        0.816\n",
      "             8          -0.31338        0.816\n",
      "             9          -0.30949        0.819\n",
      "            10          -0.30639        0.820\n",
      "            11          -0.30386        0.821\n",
      "            12          -0.30175        0.822\n",
      "            13          -0.29998        0.823\n",
      "            14          -0.29846        0.822\n",
      "            15          -0.29715        0.822\n",
      "            16          -0.29601        0.822\n",
      "            17          -0.29501        0.821\n",
      "            18          -0.29412        0.821\n",
      "            19          -0.29333        0.821\n",
      "            20          -0.29262        0.822\n",
      "            21          -0.29198        0.822\n",
      "            22          -0.29140        0.822\n",
      "            23          -0.29087        0.822\n",
      "            24          -0.29039        0.823\n",
      "            25          -0.28994        0.823\n",
      "            26          -0.28954        0.824\n",
      "            27          -0.28916        0.824\n",
      "            28          -0.28881        0.824\n",
      "            29          -0.28849        0.824\n",
      "            30          -0.28818        0.824\n",
      "            31          -0.28790        0.823\n",
      "            32          -0.28763        0.823\n",
      "            33          -0.28739        0.824\n",
      "            34          -0.28715        0.824\n",
      "            35          -0.28693        0.824\n",
      "            36          -0.28672        0.823\n",
      "            37          -0.28653        0.823\n",
      "            38          -0.28634        0.824\n",
      "            39          -0.28616        0.824\n",
      "            40          -0.28599        0.824\n",
      "            41          -0.28583        0.824\n",
      "            42          -0.28568        0.824\n",
      "            43          -0.28554        0.824\n",
      "            44          -0.28540        0.824\n",
      "            45          -0.28527        0.824\n",
      "            46          -0.28514        0.824\n",
      "            47          -0.28502        0.824\n",
      "            48          -0.28490        0.824\n",
      "            49          -0.28479        0.824\n",
      "            50          -0.28469        0.824\n",
      "            51          -0.28458        0.824\n",
      "            52          -0.28449        0.824\n",
      "            53          -0.28439        0.824\n",
      "            54          -0.28430        0.824\n",
      "            55          -0.28421        0.824\n",
      "            56          -0.28413        0.824\n",
      "            57          -0.28405        0.824\n",
      "            58          -0.28397        0.824\n",
      "            59          -0.28389        0.824\n",
      "            60          -0.28382        0.824\n",
      "            61          -0.28375        0.824\n",
      "            62          -0.28368        0.824\n",
      "            63          -0.28361        0.824\n",
      "            64          -0.28354        0.824\n",
      "            65          -0.28348        0.824\n",
      "            66          -0.28342        0.824\n",
      "            67          -0.28336        0.824\n",
      "            68          -0.28330        0.824\n",
      "            69          -0.28325        0.824\n",
      "            70          -0.28320        0.824\n",
      "            71          -0.28314        0.824\n",
      "            72          -0.28309        0.824\n",
      "            73          -0.28304        0.824\n",
      "            74          -0.28299        0.824\n",
      "            75          -0.28295        0.824\n",
      "            76          -0.28290        0.824\n",
      "            77          -0.28286        0.824\n",
      "            78          -0.28281        0.824\n",
      "            79          -0.28277        0.824\n",
      "            80          -0.28273        0.824\n",
      "            81          -0.28269        0.824\n",
      "            82          -0.28265        0.824\n",
      "            83          -0.28261        0.824\n",
      "            84          -0.28257        0.824\n",
      "            85          -0.28254        0.824\n",
      "            86          -0.28250        0.824\n",
      "            87          -0.28247        0.824\n",
      "            88          -0.28243        0.824\n",
      "            89          -0.28240        0.824\n",
      "            90          -0.28237        0.824\n",
      "            91          -0.28233        0.824\n",
      "            92          -0.28230        0.824\n",
      "            93          -0.28227        0.824\n",
      "            94          -0.28224        0.824\n",
      "            95          -0.28221        0.824\n",
      "            96          -0.28218        0.824\n",
      "            97          -0.28216        0.824\n",
      "            98          -0.28213        0.824\n",
      "            99          -0.28210        0.824\n",
      "         Final          -0.28207        0.824\n",
      "================================================================================\n",
      "Nltk ConditionalExponentialClassifier  |  Features: Feature Set 2 (first/last/counters)\n",
      "--------------------------------------------------------------------------------\n",
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.370\n",
      "             2          -0.42935        0.791\n",
      "             3          -0.37452        0.805\n",
      "             4          -0.34920        0.807\n",
      "             5          -0.33464        0.810\n",
      "             6          -0.32513        0.813\n",
      "             7          -0.31840        0.816\n",
      "             8          -0.31338        0.816\n",
      "             9          -0.30949        0.819\n",
      "            10          -0.30639        0.820\n",
      "            11          -0.30386        0.821\n",
      "            12          -0.30175        0.822\n",
      "            13          -0.29998        0.823\n",
      "            14          -0.29846        0.822\n",
      "            15          -0.29715        0.822\n",
      "            16          -0.29601        0.822\n",
      "            17          -0.29501        0.821\n",
      "            18          -0.29412        0.821\n",
      "            19          -0.29333        0.821\n",
      "            20          -0.29262        0.822\n",
      "            21          -0.29198        0.822\n",
      "            22          -0.29140        0.822\n",
      "            23          -0.29087        0.822\n",
      "            24          -0.29039        0.823\n",
      "            25          -0.28994        0.823\n",
      "            26          -0.28954        0.824\n",
      "            27          -0.28916        0.824\n",
      "            28          -0.28881        0.824\n",
      "            29          -0.28849        0.824\n",
      "            30          -0.28818        0.824\n",
      "            31          -0.28790        0.823\n",
      "            32          -0.28763        0.823\n",
      "            33          -0.28739        0.824\n",
      "            34          -0.28715        0.824\n",
      "            35          -0.28693        0.824\n",
      "            36          -0.28672        0.823\n",
      "            37          -0.28653        0.823\n",
      "            38          -0.28634        0.824\n",
      "            39          -0.28616        0.824\n",
      "            40          -0.28599        0.824\n",
      "            41          -0.28583        0.824\n",
      "            42          -0.28568        0.824\n",
      "            43          -0.28554        0.824\n",
      "            44          -0.28540        0.824\n",
      "            45          -0.28527        0.824\n",
      "            46          -0.28514        0.824\n",
      "            47          -0.28502        0.824\n",
      "            48          -0.28490        0.824\n",
      "            49          -0.28479        0.824\n",
      "            50          -0.28469        0.824\n",
      "            51          -0.28458        0.824\n",
      "            52          -0.28449        0.824\n",
      "            53          -0.28439        0.824\n",
      "            54          -0.28430        0.824\n",
      "            55          -0.28421        0.824\n",
      "            56          -0.28413        0.824\n",
      "            57          -0.28405        0.824\n",
      "            58          -0.28397        0.824\n",
      "            59          -0.28389        0.824\n",
      "            60          -0.28382        0.824\n",
      "            61          -0.28375        0.824\n",
      "            62          -0.28368        0.824\n",
      "            63          -0.28361        0.824\n",
      "            64          -0.28354        0.824\n",
      "            65          -0.28348        0.824\n",
      "            66          -0.28342        0.824\n",
      "            67          -0.28336        0.824\n",
      "            68          -0.28330        0.824\n",
      "            69          -0.28325        0.824\n",
      "            70          -0.28320        0.824\n",
      "            71          -0.28314        0.824\n",
      "            72          -0.28309        0.824\n",
      "            73          -0.28304        0.824\n",
      "            74          -0.28299        0.824\n",
      "            75          -0.28295        0.824\n",
      "            76          -0.28290        0.824\n",
      "            77          -0.28286        0.824\n",
      "            78          -0.28281        0.824\n",
      "            79          -0.28277        0.824\n",
      "            80          -0.28273        0.824\n",
      "            81          -0.28269        0.824\n",
      "            82          -0.28265        0.824\n",
      "            83          -0.28261        0.824\n",
      "            84          -0.28257        0.824\n",
      "            85          -0.28254        0.824\n",
      "            86          -0.28250        0.824\n",
      "            87          -0.28247        0.824\n",
      "            88          -0.28243        0.824\n",
      "            89          -0.28240        0.824\n",
      "            90          -0.28237        0.824\n",
      "            91          -0.28233        0.824\n",
      "            92          -0.28230        0.824\n",
      "            93          -0.28227        0.824\n",
      "            94          -0.28224        0.824\n",
      "            95          -0.28221        0.824\n",
      "            96          -0.28218        0.824\n",
      "            97          -0.28216        0.824\n",
      "            98          -0.28213        0.824\n",
      "            99          -0.28210        0.824\n",
      "         Final          -0.28207        0.824\n",
      "Dev accuracy : 0.792\n",
      "Test accuracy: 0.770\n",
      "\n",
      "Number of dev errors: 208\n",
      "\n",
      "Sample errors (first 20):\n",
      "correct=female guess=male name=Abbe\n",
      "correct=female guess=male name=Amargo\n",
      "correct=female guess=male name=Anne-Mar\n",
      "correct=female guess=male name=Babs\n",
      "correct=female guess=male name=Bebe\n",
      "correct=female guess=male name=Becky\n",
      "correct=female guess=male name=Bevvy\n",
      "correct=female guess=male name=Blondell\n",
      "correct=female guess=male name=Britt\n",
      "correct=female guess=male name=Carmon\n",
      "correct=female guess=male name=Charlott\n",
      "correct=female guess=male name=Darb\n",
      "correct=female guess=male name=Deb\n",
      "correct=female guess=male name=Doloritas\n",
      "correct=female guess=male name=Dorian\n",
      "correct=female guess=male name=Easter\n",
      "correct=female guess=male name=Em\n",
      "correct=female guess=male name=Evy\n",
      "correct=female guess=male name=Flo\n",
      "correct=female guess=male name=Flor\n"
     ]
    }
   ],
   "source": [
    "train_set   = apply_feature(feature_extractor1, train_names)\n",
    "classifier = nltk.ConditionalExponentialClassifier.train(train_set)\n",
    "\n",
    "train_and_evaluate(classifier, \"Nltk ConditionalExponentialClassifier\", feature_extractor1, \"Feature Set 2 (first/last/counters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8187368-2c13-4945-83eb-3388e32995d4",
   "metadata": {},
   "source": [
    "### Model Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27aea695-f782-47be-b62f-80f1f7ade8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Nltk SklearnClassifier  |  Features: Feature Set 1 (last_letter/name length/firstletter/end_vowel)\n",
      "--------------------------------------------------------------------------------\n",
      "Dev accuracy : 0.824\n",
      "Test accuracy: 0.778\n",
      "\n",
      "Number of dev errors: 176\n",
      "\n",
      "Sample errors (first 20):\n",
      "correct=female guess=male name=Amargo\n",
      "correct=female guess=male name=Andromache\n",
      "correct=female guess=male name=Anne-Mar\n",
      "correct=female guess=male name=Aphrodite\n",
      "correct=female guess=male name=Ardath\n",
      "correct=female guess=male name=Ashlen\n",
      "correct=female guess=male name=Audre\n",
      "correct=female guess=male name=Aurore\n",
      "correct=female guess=male name=Babs\n",
      "correct=female guess=male name=Becky\n",
      "correct=female guess=male name=Blondell\n",
      "correct=female guess=male name=Britt\n",
      "correct=female guess=male name=Carmon\n",
      "correct=female guess=male name=Charis\n",
      "correct=female guess=male name=Charlott\n",
      "correct=female guess=male name=Chicky\n",
      "correct=female guess=male name=Darb\n",
      "correct=female guess=male name=Deb\n",
      "correct=female guess=male name=Doloritas\n",
      "correct=female guess=male name=Dove\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "classifier = nltk.SklearnClassifier(LinearSVC())\n",
    "train_and_evaluate(classifier, \"Nltk SklearnClassifier\", feature_extractor2,  \"Feature Set 1 (last_letter/name length/firstletter/end_vowel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f4cf4b8-0c0b-4010-b073-1c9b9a52ab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Nltk SklearnClassifier  |  Features: Feature Set 2 (first/last/count)\n",
      "--------------------------------------------------------------------------------\n",
      "Dev accuracy : 0.824\n",
      "Test accuracy: 0.778\n",
      "\n",
      "Number of dev errors: 176\n",
      "\n",
      "Sample errors (first 20):\n",
      "correct=female guess=male name=Amargo\n",
      "correct=female guess=male name=Andromache\n",
      "correct=female guess=male name=Anne-Mar\n",
      "correct=female guess=male name=Aphrodite\n",
      "correct=female guess=male name=Ardath\n",
      "correct=female guess=male name=Ashlen\n",
      "correct=female guess=male name=Audre\n",
      "correct=female guess=male name=Aurore\n",
      "correct=female guess=male name=Babs\n",
      "correct=female guess=male name=Becky\n",
      "correct=female guess=male name=Blondell\n",
      "correct=female guess=male name=Britt\n",
      "correct=female guess=male name=Carmon\n",
      "correct=female guess=male name=Charis\n",
      "correct=female guess=male name=Charlott\n",
      "correct=female guess=male name=Chicky\n",
      "correct=female guess=male name=Darb\n",
      "correct=female guess=male name=Deb\n",
      "correct=female guess=male name=Doloritas\n",
      "correct=female guess=male name=Dove\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.SklearnClassifier(LinearSVC())\n",
    "train_and_evaluate(classifier, \"Nltk SklearnClassifier\", feature_extractor2, \"Feature Set 2 (first/last/count)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6af26-7302-431e-8cfd-f2c15ff0a52d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-py3.13",
   "language": "python",
   "name": "env-py3.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
